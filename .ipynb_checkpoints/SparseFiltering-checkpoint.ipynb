{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loading face #%05d / %05d', 1, 70)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n",
      "(250, 250)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "filepaths =[]\n",
    "for index in range(81):\n",
    "    filepaths.append( \"Ads/ad\"+str(index+1)+\".jpg\" )\n",
    "\n",
    "from sparse_filtering import SparseFiltering\n",
    "def _load_imgs(file_paths, slice_, color, resize):\n",
    "    \"\"\"Internally used to load images\"\"\"\n",
    "\n",
    "   \n",
    "    try:\n",
    "        try:\n",
    "            from scipy.misc import imread\n",
    "        except ImportError:\n",
    "            from scipy.misc.pilutil import imread\n",
    "        from scipy.misc import imresize\n",
    "    except ImportError:\n",
    "        raise ImportError(\"The Python Imaging Library (PIL)\"\n",
    "                          \" is required to load data from jpeg files\")\n",
    "\n",
    "    \n",
    "    default_slice = (slice(0, 250), slice(0, 250))\n",
    "    if slice_ is None:\n",
    "        slice_ = default_slice\n",
    "    else:\n",
    "        slice_ = tuple(s or ds for s, ds in zip(slice_, default_slice))\n",
    "\n",
    "    h_slice, w_slice = slice_\n",
    "    h = (h_slice.stop - h_slice.start) // (h_slice.step or 1)\n",
    "    w = (w_slice.stop - w_slice.start) // (w_slice.step or 1)\n",
    "\n",
    "    if resize is not None:\n",
    "        resize = float(resize)\n",
    "        h = int(resize * h)\n",
    "        w = int(resize * w)\n",
    "\n",
    "    n_faces = len(file_paths)\n",
    "    if not color:\n",
    "        faces = np.zeros((n_faces, h, w), dtype=np.float32)\n",
    "    else:\n",
    "        faces = np.zeros((n_faces, h, w, 3), dtype=np.float32)\n",
    "\n",
    " \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loading face #%05d / %05d\", i + 1, n_faces)\n",
    "\n",
    "    \n",
    "        img = imread(file_path)\n",
    "        if img.ndim is 0:\n",
    "            raise RuntimeError(\"Failed to read the image file %s, \"\n",
    "                               \"Please make sure that libjpeg is installed\"\n",
    "                               % file_path)\n",
    "\n",
    "        face = np.asarray(img[slice_], dtype=np.float32)\n",
    "        face /= 255.0 \n",
    "        if resize is not None:\n",
    "            face = imresize(face, resize)\n",
    "        if not color:\n",
    "            face = face.mean(axis=2)\n",
    "      \n",
    "        faces[i, ...] = face\n",
    "\n",
    "    return faces\n",
    "\n",
    "faces = _load_imgs(filepaths,None,None,None)  \n",
    "\n",
    "n_samples,_,_ = faces.shape\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "patch_width = 16\n",
    "\n",
    "patches = [extract_patches_2d(faces[i], (patch_width, patch_width),\n",
    "                              max_patches=25, random_state=i)\n",
    "              for i in range(n_samples)]\n",
    "patches = np.array(patches).reshape(-1, patch_width * patch_width)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(patches[i].reshape(patch_width, patch_width), cmap=plt.get_cmap('gray'))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "_ = plt.suptitle(\"Image Patches for features\")\n",
    "\n",
    "\n",
    "\n",
    "n_features = 64  \n",
    "estimator = SparseFiltering(n_features=n_features, \n",
    "                            maxfun=200,  \n",
    "                            iprint=10)  \n",
    "features = estimator.fit_transform(patches)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(estimator.w_.shape[0]):\n",
    "    plt.subplot(int(np.sqrt(n_features)), int(np.sqrt(n_features)), i + 1)\n",
    "    plt.pcolor(estimator.w_[i].reshape(patch_width, patch_width),\n",
    "               cmap=plt.cm.RdYlGn, vmin=estimator.w_.min(),\n",
    "               vmax=estimator.w_.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(\"Feature %4d\" % i)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "histogram = plt.figure()\n",
    "plt.hist(list(features.flat), bins=50)\n",
    "plt.xlabel(\"Activation\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Feature activation histogram\")\n",
    "histogram.savefig('historgram.png')\n",
    "\n",
    "lifetime_sparsity=plt.figure()\n",
    "activated_features = (features > 0.1).mean(0)\n",
    "plt.hist(activated_features)\n",
    "plt.xlabel(\"Feature activation ratio over all examples\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Lifetime Sparsity Histogram\")\n",
    "lifetime_sparsity.savefig('lifetime_sparsity.png')\n",
    "\n",
    "population_sparsity=plt.figure()\n",
    "activated_features = (features > 0.1).mean(1)\n",
    "plt.hist(activated_features, bins=10)\n",
    "plt.xlabel(\"Ratio of active features in example\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Population Sparsity Histogram\")\n",
    "population_sparsity.savefig('population_sparsity.png')\n",
    "\n",
    "\n",
    "dispersal_histogram=plt.figure()\n",
    "plt.hist((features**2).mean(0))\n",
    "plt.xlabel(\"Mean Squared Feature Activation\")\n",
    "plt.ylabel(\"Count\")\n",
    "_ = plt.title(\"Dispersal Histogram\")\n",
    "dispersal_histogram.savefig('dispersal_histogram.png')\n",
    "\n",
    "\n",
    "\n",
    "n_features2 = 10   # How many features are learned\n",
    "estimator2 = SparseFiltering(n_features=n_features2, \n",
    "                             maxfun=200,  # The maximal number of evaluations of the objective function\n",
    "                             iprint=10)  # after how many function evaluations is information printed\n",
    "                                        # by L-BFGS. -1 for no information\n",
    "features2 = estimator2.fit_transform(features)\n",
    "\n",
    "\n",
    "second_layer=plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(n_features2):\n",
    "    # Select the top-6 layer-1 features used within the layer-2 features\n",
    "    indices = np.argsort(estimator2.w_[i])[-6:][::-1]\n",
    "    for j, ind in enumerate(indices):\n",
    "        plt.subplot(6, n_features2, j*n_features2 + i + 1)\n",
    "        plt.pcolor(estimator.w_[i].reshape(patch_width, patch_width),\n",
    "               cmap=plt.cm.RdYlGn, vmin=estimator.w_.min(),\n",
    "               vmax=estimator.w_.max())\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.01)\n",
    "second_layer.savefig('second_layer.png')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "X=features2\n",
    "n_clusters=5\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "colors = cm.spectral(cluster_labels.astype(float) / n_clusters)\n",
    "ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "ax2.scatter(centers[:, 0], centers[:, 1],\n",
    "                marker='o', c=\"white\", alpha=1, s=200)\n",
    "\n",
    "for i, c in enumerate(centers):\n",
    "    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "\n",
    "ax2.set_title(\"The visualization of the clustered data.\")\n",
    "ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('Clusers.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
